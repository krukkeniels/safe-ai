# safe-ai environment configuration
# Copy to .env and customize: cp .env.example .env
# DO NOT commit .env to git (it's in .gitignore)

# === SSH Access ===
# Your SSH public key (for container access)
SAFE_AI_SSH_KEY=~/.ssh/id_ed25519.pub

# Host port for SSH connections
SAFE_AI_SSH_PORT=2222

# === Allowlist ===
# Path to allowlist file (default: ./allowlist.yaml)
# SAFE_AI_ALLOWLIST=./allowlist.yaml

# Extra domains to allow (comma-separated, merged with allowlist file)
# SAFE_AI_DEFAULT_DOMAINS=

# === Sandbox Runtime ===
# Container runtime: "runc" (default) or "runsc" (gVisor, kernel-level isolation)
# gVisor prevents container escape via kernel exploits.
# Install first: ./scripts/install-gvisor.sh
# SAFE_AI_RUNTIME=runsc

# === Resource Limits ===
# Sandbox container resources (adjust for your machine)
SAFE_AI_SANDBOX_MEMORY=8g
SAFE_AI_SANDBOX_CPUS=4

# === Audit Logging ===
# Enable with: docker compose --profile logging up -d
# Omit SAFE_AI_LOKI_URL to use local Loki + Grafana (zero-config tryout).
# Set it to ship logs to a central Loki server instead.
# SAFE_AI_LOKI_URL=https://user:pass@loki.internal.example.com:3100
# SAFE_AI_HOSTNAME=dev-workstation-01
# SAFE_AI_GRAFANA_PORT=3000
# SAFE_AI_GRAFANA_PASSWORD=admin

# === LLM Gateway (local dev/testing only) ===
# In production, orgs bake these into the proxy image.
# See: examples/gateway-proxy.Dockerfile
# SAFE_AI_GATEWAY_DOMAIN=llm-gateway.example.com
# SAFE_AI_GATEWAY_TOKEN=your-shared-secret-here
